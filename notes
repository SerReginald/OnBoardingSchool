neurone: séries d'entrées pondéré 
une sortie , evalué par rapport à un hyperplan, au dessus : 1 , en dessous : 0

cybernétique : science des sytemes bouclé 

approche symbolique , faire de la résolution par algorithmes (successions de IF codé à la main)
approche connectionniste , réseaux de neurones 
	-> nécessite un OU exclusif , ce qui nécessite 3 couches de neurones (raison du premier abandon de l'IA)

1980 : premier réseau de neurones profond 

réseaux : falcon , claude 2 ...
early open source LLM : BLOOM (gpt-3 alternative)
alpaca from stanford 
Llama2 
github alternative for open source IA model : Huggingface 
(can run locally) (low cost)

Llama on smartphone for 2024, locally

protections sur les réseaux , (suppression messages vulgaire, sensible...) diminuent drastiquement les perfs


machine learning :
	SVM
	Clustering
	Decision tree
	regression

_______________________________________

apprentissage supervisé , on connait les étiquettes , l'algo apprend à prédire et connaitre
	classification
	segmentation (découper l'image)
	génération de texte, images

apprentissage non supervisé : données non étiquetées , l'algo apprend une structure inhérente
	détection d'anomalies
	clustering

pas vu cette semaine : 
	apprentissage par renforcement
		robot
		réseaux sociaux
		jeux vidéos
	apprentissage semi-supervisé : seulement certaines étiquettes
		co-apprentissage
		étiquetage


classification / régression
	régression
		la valeur en sortie du neure est un nombre réel (sortie continue)
	classification
		la valeur en sortie est discrète (catégorie)
		classification binaire:
			oui/non
			vrai/faux
			chien/chat
			...
		classification multi-classes
			pays
			villes
			patologie
			...
		ranking (étiquettes ordonnées)
			age
			vêtements
			...

Gérer les données
	Ne jamais donner les mêmes données pour l'apprentissage et pour le test (logique)
	- données d'apprentissage
		mise au point du modèle
	- données de test	
		évaluation du modèle

	données catégorielles
		vecteurs
	données continues
		nécessite, un centrage et une normalisation


<!>	<!>	<!>
Problèmes classique :

	1) manque de données
	2) données non représentative
	3) données de piètre qualité
		- incomplète (manque de paramètres qui définissent l'échantillon)
		- bruité (paramètres qui ne servent à rien)
	4) données inutiles non corrélées au pb
	5) classes non équilibrés 

évaluer le modèle
	Le modèle répond-il au PB ?

	Définir un critère d'évaluation du modèle 
		après apprentissage pour l'évaluation
		pendant l'apprentissave pour minimiser l'érreur

	Bien définire la classe du problème
		régression
		classification

	le critère peut être modifier pour s'adapter au problème à traiter
		classes non balancées
		information.a.priori

	évaluation : REGRESSION
		"Mean squarred error (MSE)"
		"score R²"
			Diviser le MSE par la somme des sorties attendu
			moins sensible aux aberrations que le MSE

	évaluation : CLASSIFICATION BINAIRE
		Précision
			on détecte les vrais négatifs et les faux positifs , 
			divisé par la taille de l'échantillon

		Precision (eng)
			capacité du modèle à ne pas prévoir négativement des valeurs positives
				Vrais positifs / (Vrai positif + faux positif)
		Recall
			capacité du modèle à prédire les valeurs positives
				Vrai positif / (vrai positif + faux négatif)

		harmonie
			moyenne de précision(eng) et recall

		ROC Curve , courbe de performances du modèle en fonction du seuil de classification

		AUC (area under the curve)

	évaluation : CLASSIFICATION MULTI-CLASSE
		métriques binaires

		matrice de confusion
			matrice regroupand toutes les classes et les résultats , pour déterminer quels sont les sorties , et surtout les erreurs de l'IA

	principe général de l'apprentissage :
		itératif
			choix du modèle -> configuration modèle -> prétraitement -> séparation apprentissage / validation -> base de données -> choix du modèle -> ...

	






https://gitlab.in2p3.fr/aissai/onboardingschool

<!> attention surapprentissage
on fait un premier "développement : entrainement"
on observe l'évolution du taux d'erreurs, l'objectif est de ne jamais être en "sous entrainement" (erreur élevé) , ni "sur entrainement" (erreur trop faible , on serait dans un cas ou l'apprentissage aurait été fixé sur un jeu de test , et incapable de travailler sur un autre jeu)

arbre de décision
contexte : supervisé (on connait les données)
	indice de Gini : indice de qualité lorsque faible
	indice de pureté : pour chaque noeud, multiplication de la population attendu sur la population totale, multiplié par l'indice de Gini du noeud 
		addition du total
			150 de pop , 2 branches , une qui attend 50 avec un gini de 0 , une qui attend 100 avec un gini de 0.5
			50/150*0+100/150*0.5=0.33 (indice élevé)

	{} = objectif, donner une évaluation de l'arbre. Via le Gini on calcul la pureté, qui donne la qualité de l'arbre
	(ça aide à connaitre la profondeur nécessaire de l'arbre (2 , 3 , 4 ... couches) )
	uniquement utile lors de la création de l'arbre, on évalue sa qualité via un test ensuite
	uniquement en supervisé


SVM
	(support vecteurs machine)
	on vise à séparer les éléments par un hyperplan
	si les données ne sont pas séparable, on cherche à transformer l'espace , en espace d'une plus grande dimension dans lequel apparaitra une séparation linéaire







Malédiction de la dimension :
	Augmentation de l'espace à découvrir
	1 dimension : 40 points
	2 dimensions : 40 * 40 points
	3 dimensions : 40 * 40 * 40 points 
	...

	on vise alors à bien travailler son jeu de données
	pour minimiser le nombre de paramètres , chaque dimension correspondant à un paramètre , et aux valeurs de chaque donnée par rapport à ce paramètre
	(par exemple on vise à minimisez le nombre de choses à reconnaitre pour définir la race d'un animal) 

	




https://mlflow.org/
Enregistrer un modèle d'IA que l'on à pu produire 
(logiciel gratuit à installer sur son PC )





Comment optimiser les HyperParamètres ?

Hyperparamètre :
	toutes les informations et les paramètres utilisé pour configurer un réseau de neurones définit son architecture, ses performances
		- nombre de couches
		- nombre de neurones par couches
		- nombre d'époques
		- drop out (coupures aléatoire entre certains couches) 
			--> contreversé (à essayer mais pas garantie 100% utile)
		- quel type de fonction coût
		- quel type de fonction d'activations
		...........

	<!> TOUT CONFIGURER PEUT PRENDRE DES ANNEES <!>
		--> meilleur réseau possible : impossible, l'évolution d'un réseau par rapport au temps de travail est logarithmique

	<??> quand on commence la création d'un réseau de neurones , on commence par un faible nombre de couches, plus facile de l'augmenter que de le diminuer

	Optimisation automatique des hyperparamètres :
		- Orion
		- Optuna
		- KerasTuner (quand on utilise l'API keras)

	facile d'optimiser les hyperParamètres en Parallèle. On test toutes les possibilités et on choisit celle qui nous convient le mieux

	.... L'optimisateurs de paramètres , est à paramètrer ....



IA création d'images : diffusion :
	auto-encoder entrainé au débruitage
	Entrainé par un enchainement d'ajouts de bruits sur une image 

		image 	-> 	image * bruit 	-> image * bruit * bruit 	-> 	image * bruit * bruit * bruit 	-> ...
		<1>			<2>					<3>							<4>

		on va ici entrainer différents réseaux de neurones , à passer de 4 à 3 à 2 à 1. Puis, on pourra générer des images depuis une valeur aléatoire. 
		(permet autant de réparer une image dégradé que d'en généré des totalement neuve)






















































































{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification de formes à l'aide d'un réseau de convolution : utilisation des callbacks\n",
    "\n",
    "> Author: Françoise Bouvet (IJCLab, CNRS)  \n",
    "> Email: <francoise.bouvet@ijclab.in2p3.fr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introduction](#Introduction)\n",
    "2. [Préparation des données](#Préparation-des-données)\n",
    "3. [Structure du réseau](#Structure-du-réseau)\n",
    "4. [Apprentissage](#Apprentissage)\n",
    "5. [Evaluation](#Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "L'objectif de ce TP est d'apprendre à utiliser les callbacks, mécanismes très utiles pour suivre l'évolution de l'apprentissage et/ou réguler l'apprentissage. Vous pouvez reprendre votre propre TP précédent et le faire évoluer. \n",
    "\n",
    "Les images sont issues de la base de données de la plateforme [kaggle](https://www.kaggle.com/)  \n",
    "\n",
    "Pour vous aider, vous trouverez des informations complémentaires sur la librairie [keras](https://keras.io/getting_started/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import lecture_shape_1channel\n",
    "\n",
    "rep_data = \"../datasets/data_shape/\"\n",
    "lst_shape = ['circle', 'ellipse', 'rectangle', 'square', 'triangle']\n",
    "\n",
    "# Read input data and transform output into one hot encoding\n",
    "input_train_raw, output_train_raw = lecture_shape_1channel(rep_data + \"train/\", \"*.png\", lst_shape)\n",
    "\n",
    "if input_train_raw is None or not np.any(input_train_raw):\n",
    "    print(f'Aucun fichier {extension} trouvé dans {dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Normalize input data\n",
    "input_train = input_train_raw.astype('float32') / 255.\n",
    "# Transform output into one hot encoding\n",
    "output_train = to_categorical(output_train_raw)\n",
    "\n",
    "# Shuffle input data\n",
    "ind = np.arange(0, np.shape(input_train)[0])\n",
    "np.random.shuffle(ind)\n",
    "\n",
    "# Apply to data ; \n",
    "input_train = input_train[ind]\n",
    "output_train = output_train[ind]\n",
    "\n",
    "print(f'Il y a {input_train.shape[0]} échantillons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure du réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "\n",
    "# Network definition : add successive layers\n",
    "model = Sequential()\n",
    "\n",
    "# Convolution layers\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(64, 64, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Reshape input 1D vector\n",
    "model.add(Flatten())\n",
    "\n",
    "# Full connected layer (MLP)\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "# # Output layer\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation of the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "\n",
    "# Display the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks\n",
    "\n",
    "Un callback est une **tâche effectuée à chaque époque**. Plusieurs callbacks sont **prédéfinis** :\n",
    "\n",
    "- ReduceLROnPlateau : réduit le learning rate quand une métrique atteint un plateau\n",
    "- EarlyStopping : arrêt lorsqu’une métrique donnée arrête de progresser\n",
    "- ModelCheckpoint : sauvegarde régulière du modèle ou des poids\n",
    "- TensorBoard : pour la visualisation de l’apprentissage avec TensorBoard\n",
    "- BackupAndRestore : en cas d’interruption\n",
    "- LearningRateScheduler : appel d’une fonction pour calculer le learning  rate\n",
    "- RemoteMonitor : envoie de données à un serveur\n",
    "\n",
    "\n",
    "Il est aussi possible de définir son propre callback. Il dérive de la classe de base **Callback**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "\n",
    "class GenereImage(Callback):\n",
    "\n",
    "    def __init__(self, model):\n",
    "\n",
    "        self._model = model\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "        n = 2\n",
    "        if epoch % n == n - 1:\n",
    "            print(f\"C'est l'époque {epoch}  du modèle {model.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "# Decrease the learning rate factor\n",
    "reduce_lr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.0001)\n",
    "# Suivi de l'appentissage par Tensorboard\n",
    "tensorboard_cb = TensorBoard(log_dir=\"./logs\")\n",
    "# Callback personnalisé\n",
    "custom_cb = GenereImage(model)\n",
    "\n",
    "cb = [reduce_lr_cb, tensorboard_cb, custom_cb]\n",
    "\n",
    "history = model.fit(input_train, output_train,\n",
    "                    epochs=20,\n",
    "                    validation_split=0.2,\n",
    "                    batch_size=32,\n",
    "                    verbose=0,  # pas d'affichage \n",
    "                    callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import draw_history\n",
    "\n",
    "draw_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enregistrement du model entraîné pour une utilisation ultérieure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "model.save('./model_shape.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test data\n",
    "input_test, output_test = lecture_shape_1channel(rep_data + \"test/\", \"*.png\", lst_shape)\n",
    "# Normalize test data\n",
    "input_test = input_test.astype('float32') / 255.\n",
    "# Transform output into one hot encoding\n",
    "output_test = to_categorical(output_test)\n",
    "\n",
    "# Evaluate the model ; the two parameters are the input_test array and the output_test array\n",
    "sum_score = model.evaluate(input_test, output_test)\n",
    "print(\"Data test : loss %.3f accuracy %.3f\" % (sum_score[0], sum_score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

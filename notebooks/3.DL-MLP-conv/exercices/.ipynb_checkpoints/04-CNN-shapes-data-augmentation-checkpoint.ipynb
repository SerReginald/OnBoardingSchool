{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification de formes à l'aide d'un réseau de convolution : augmentation de données\n",
    "\n",
    "> Author: Françoise Bouvet (IJCLab, CNRS)  \n",
    "> Email: <francoise.bouvet@ijclab.in2p3.fr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introduction](#Introduction)\n",
    "2. [Préparation des données](#Préparation-des-données)\n",
    "3. [Structure du réseau](#Structure-du-réseau)\n",
    "4. [Apprentissage](#Apprentissage)\n",
    "5. [Evaluation](#Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "L'objectif de ce TP est d'essayer d'améliorer les résultats en pratiquant de l'augmentation de données par transformations géométriques.\n",
    "\n",
    "Les images sont issues de la base de données de la plateforme [kaggle](https://www.kaggle.com/)  \n",
    "\n",
    "Pour vous aider, vous trouverez des informations complémentaires sur la librairie [keras](https://keras.io/getting_started/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import lecture_shape_1channel\n",
    "\n",
    "rep_data = \"../datasets/data_shape/\"\n",
    "lst_shape = ['circle', 'ellipse', 'rectangle', 'square', 'triangle']\n",
    "\n",
    "# Read input data and transform output into one hot encoding\n",
    "input_train_raw, output_train_raw = lecture_shape_1channel(rep_data + \"train/\", \"*.png\", lst_shape)\n",
    "\n",
    "if input_train_raw is None or not np.any(input_train_raw):\n",
    "    print(f'Aucun fichier {extension} trouvé dans {dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Normalize input data\n",
    "input_train = input_train_raw.astype('float32') / 255.\n",
    "# Transform output into one hot encoding\n",
    "output_train = to_categorical(output_train_raw)\n",
    "\n",
    "# Shuffle input data\n",
    "ind = np.arange(0, np.shape(input_train)[0])\n",
    "np.random.shuffle(ind)\n",
    "\n",
    "# Apply to data ; \n",
    "input_train = input_train[ind]\n",
    "output_train = output_train[ind]\n",
    "\n",
    "print(f'Il y a {input_train.shape[0]} échantillons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'une couche de transformation\n",
    "On peut utiliser RandomFlip(...) et RandomZoom(...).  \n",
    "Utiliser l'option adéquate pour le paramètre fill_mode de RandomZoom().  \n",
    "Attention,compte tenu des données, RandomRotation() n'est pas approprié car changerait le type de forme ; idem pour les modifications de contraste car les images sont binaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import RandomFlip, RandomZoom\n",
    "\n",
    "# Add flip and zoom ; be careful with the option fill_mode RandomFlip(...) et RandomZoom(...).\n",
    "data_augmentation = keras.Sequential([\n",
    "    ...\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérification sur quelques images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the result on some images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i, image in enumerate(input_train[0:9]):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(image)\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_image = data_augmentation(input_train)\n",
    "print(np.shape(augmented_image))\n",
    "\n",
    "for i, image in enumerate(augmented_image[0:9]):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(image)\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure du réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "# Network definition : add successive layers\n",
    "model = Sequential()\n",
    "\n",
    "# The first layer is the augmentation layer \n",
    "model.add(data_augmentation)\n",
    "\n",
    "# Convolution layers\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation of the model\n",
    "model.compile(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "# Decrease the learning rate factor\n",
    "reduce_lr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.0001)\n",
    "\n",
    "cb = [reduce_lr_cb]\n",
    "\n",
    "history = model.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import draw_history\n",
    "\n",
    "draw_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test data\n",
    "input_test, output_test = lecture_shape_1channel(rep_data + \"test/\", \"*.png\", lst_shape)\n",
    "# Normalize test data\n",
    "input_test = input_test.astype('float32') / 255.\n",
    "# Transform output into one hot encoding\n",
    "output_test = to_categorical(output_test)\n",
    "\n",
    "# Test set shuffle only aims to display samples from all the classes\n",
    "ind = np.arange(np.shape(input_test)[0])\n",
    "np.random.shuffle(ind)\n",
    "input_test = np.array(input_test)[ind]\n",
    "output_test =np.array(output_test)[ind]\n",
    "\n",
    "# Evaluate the model ; the two parameters are the input_test array and the output_test array\n",
    "sum_score = model.evaluate(input_test, output_test)\n",
    "print(\"Data test : loss %.3f accuracy %.3f\" % (sum_score[0], sum_score[1]))\n",
    "\n",
    "# Prediction ; the input parameter is the input_test array ; return value is the prediction array\n",
    "output_predict = model.predict(input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import draw_multiple_images\n",
    "\n",
    "# Display the test images and the predicted class\n",
    "n=min(40, np.shape(input_test)[0])\n",
    "nb_col = 8\n",
    "draw_multiple_images(input_test[0:n], output_test[0:n], output_predict[0:n], lst_shape, nb_col, np.shape(input_test)[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

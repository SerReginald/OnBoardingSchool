{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Auto-Encoder\n",
    "\n",
    "L'objectif de ce TP est de comprendre comment crée un auto encodeur et de tester certain de ces applications."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sklearn Digit\n",
    "\n",
    "Pour commencer nous allons appliquer l'auto-encoder au jeu de chiffres vu dans le TP sur l'Unsupervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "\n",
    "train = digits.data[:1500] / 16.0\n",
    "test = digits.data[1500:] / 16.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 10, figsize=(10, 6), subplot_kw={'xticks': [], 'yticks': []})\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(test[i].reshape(8,8), cmap='binary_r')\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construisons un modèle d'Auto-Encoder avec Keras, n'hésitez pas à aller revoir le cours pour visualiser sa structure. Il se compose de deux moitiés ayant chacune le même nombre de couches. La première projette les données sur un espace latent de faible dimension, le second par de cet espace latent pour reconstruire l'image initiale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Créeons un autoencodeur simple\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Encoder\n",
    "\n",
    "model.add(Dense(48, activation='relu', input_dim=train.shape[1]))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "\n",
    "# Decoder\n",
    "model.add(Dense(48, activation='relu'))\n",
    "model.add(Dense(train.shape[1], activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train, train,\n",
    "          epochs=50,    \n",
    "          batch_size=5,       \n",
    "          validation_split=0.2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testons maintenant notre auto-encodeur sur les données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(test)\n",
    "\n",
    "fig, axes = plt.subplots(5, 10, figsize=(10, 6), subplot_kw={'xticks': [], 'yticks': []})\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(output[i].reshape(8,8), cmap='binary_r')\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "\n",
    "Les nombres de sklearn ne contiennent pas beaucoup de donnée et sont très simples. Nous allons donc essayer avec des images plus complexes provenant de MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Chargement des données\n",
    "\n",
    "Les données sont extraine, normalisé et projeté en sur un vecteur 1D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Flaten the data\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_digit(x, y):\n",
    "    fig, ax = plt.subplots(5, 5, figsize=(10, 10))\n",
    "\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            ax[i][j].imshow(x[i+5*j].reshape(28,28))\n",
    "            ax[i][j].tick_params(\n",
    "                which='both',      \n",
    "                bottom=False,      \n",
    "                top=False,\n",
    "                left=False,\n",
    "                labelbottom=False,\n",
    "                labelleft=False) \n",
    "            ax[i][j].set_title(y[i+5*j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digit(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réécrivez un nouvel auto-encodeur adapté aux données MNIST. Essayez un espace latte de dimension 2. Cela nous permettra de visualiser par la suite les différents nombres sur cet espace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Créeons un autoencodeur simple\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Encoder\n",
    "\n",
    "model.add(Dense(512, activation='relu', input_dim=x_train.shape[1]))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(2, activation='relu'))\n",
    "\n",
    "# Decoder\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(x_train.shape[1], activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, x_train,\n",
    "          epochs=20,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(x_test)\n",
    "plot_digit(output, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous avec utiliser un espace latent de dimension 2 pour pouvez visualiser la position des nombres sur l'espace latent grâce au lignes suivantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the latent space of the model\n",
    "encoder = keras.Model(model.input, model.layers[2].output)\n",
    "z = encoder.predict(x_test)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(z[:, 0], z[:, 1], c=y_test, cmap='tab10')\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les autos-encodeurs peuvent être utilisés pour le débruitage d'images, essayons de les utiliser ainsi. Commençons par générer de nouvelles données ou 40% des pixels sont égaux ont une valeur de 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add nise by setion 30% of input to 0\n",
    "x_train_noisy = x_train.copy()\n",
    "x_train_noisy[np.random.random(x_train_noisy.shape) < 0.4] = 1\n",
    "x_test_noisy = x_test.copy()\n",
    "x_test_noisy[np.random.random(x_test_noisy.shape) < 0.4] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(x_test_noisy)\n",
    "plot_digit(output, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un problème avec les auto-encoder est qu'ils performent mal sur des données diffèrent trop de leurs données d'entraînement. Cela peut être utilisé pour faire de la détection d'anomalie (ou une sortie très différente de l'entrée correspond à des données inattendues). Pour résoudre ce problème dans le cadre de notre débruitage nous allons utiliser des données bruitées pour entraîner notre réseau. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Créeons un autoencodeur simple\n",
    "\n",
    "model_noisy = Sequential()\n",
    "\n",
    "# Encoder\n",
    "\n",
    "model_noisy.add(Dense(512, activation='relu', input_dim=x_train.shape[1]))\n",
    "model_noisy.add(Dense(120, activation='relu'))\n",
    "model_noisy.add(Dense(16, activation='relu'))\n",
    "\n",
    "# Decoder\n",
    "model_noisy.add(Dense(120, activation='relu'))\n",
    "model_noisy.add(Dense(512, activation='relu'))\n",
    "model_noisy.add(Dense(x_train.shape[1], activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_noisy.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_noisy.fit(x_train_noisy, x_train,\n",
    "          epochs=20,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant tester notre modèle sur des images de chiffres manuscrits bruité et non bruité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model_noisy.predict(x_test)\n",
    "plot_digit(output, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model_noisy.predict(x_test_noisy)\n",
    "plot_digit(output, y_test)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
